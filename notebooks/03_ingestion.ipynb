{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Ingest into OpenSearch\n",
    "\n",
    "Reads the embeddings Delta table and bulk-loads everything into the OpenSearch index running in Docker.\n",
    "\n",
    "### The tuning exercise\n",
    "Try different `BATCH_SIZE` values (100, 500, 1000, 2000) and record the elapsed time. This is your \"Uber 12.5 hrs → 2.5 hrs\" story — document the table in your README.\n",
    "\n",
    "| batch_size | elapsed (s) | docs/s |\n",
    "|-----------|------------|--------|\n",
    "| 100       | ?          | ?      |\n",
    "| 500       | ?          | ?      |\n",
    "| 1000      | ?          | ?      |\n",
    "| 2000      | ?          | ?      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d9c8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.helpers import bulk\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc10657",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_IN      = \"../delta_lake/embeddings/restaurants\"\n",
    "INDEX_NAME    = \"restaurants\"\n",
    "VECTOR_DIM    = 1024   # text-embedding-3-small\n",
    "BATCH_SIZE    = 500    # <-- tune this and record results\n",
    "\n",
    "OS_HOST = \"localhost\"\n",
    "OS_PORT = 9200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db227e5",
   "metadata": {},
   "source": [
    "## 1. Connect to OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fc68606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "client = OpenSearch(\n",
    "    hosts=[{\"host\": OS_HOST, \"port\": OS_PORT}],\n",
    "    http_compress=True,\n",
    ")\n",
    "\n",
    "info = client.info()\n",
    "print(f\"OpenSearch version: {info['version']['number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eecbf1",
   "metadata": {},
   "source": [
    "## 2. Create index with HNSW mapping\n",
    "\n",
    "- `m=16`: each node connects to 16 neighbours during graph construction — higher = better recall, more memory\n",
    "- `ef_construction=128`: size of the candidate list at build time — higher = slower build, better graph quality\n",
    "- `ef_search=100`: size of the candidate list at query time — tune at query time without rebuilding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "326ffa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing index 'restaurants'\n",
      "Index 'restaurants' created  (dim=1024, engine=nmslib)\n"
     ]
    }
   ],
   "source": [
    "# Drop and recreate for a clean slate\n",
    "if client.indices.exists(index=INDEX_NAME):\n",
    "    client.indices.delete(index=INDEX_NAME)\n",
    "    print(f\"Dropped existing index '{INDEX_NAME}'\")\n",
    "\n",
    "index_config = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"knn\": True,\n",
    "            \"knn.algo_param.ef_search\": 100,\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0,\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"restaurant_id\": {\"type\": \"keyword\"},\n",
    "            \"name\":          {\"type\": \"text\"},\n",
    "            \"cuisines\":      {\"type\": \"text\"},\n",
    "            \"location\":      {\"type\": \"text\"},\n",
    "            \"rating\":        {\"type\": \"float\"},\n",
    "            \"cost_for_two\":  {\"type\": \"integer\"},\n",
    "            \"text_for_embedding\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": VECTOR_DIM,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"engine\": \"nmslib\",   # supports up to 16k dims (lucene caps at 1024)\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \"parameters\": {\n",
    "                        \"m\": 16,\n",
    "                        \"ef_construction\": 128,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "client.indices.create(index=INDEX_NAME, body=index_config)\n",
    "print(f\"Index '{INDEX_NAME}' created  (dim={VECTOR_DIM}, engine=nmslib)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78edf8",
   "metadata": {},
   "source": [
    "## 3. Read embeddings from Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87aa76c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to ingest: 9,542\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ZomatoSemanticSearch-Ingestion\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "df = spark.read.format(\"delta\").load(DELTA_IN)\n",
    "print(f\"Rows to ingest: {df.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a488dfa",
   "metadata": {},
   "source": [
    "## 4. Bulk ingest with tunable batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bfb1ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  500 docs  |  1.5s elapsed\n",
      "  1,000 docs  |  2.9s elapsed\n",
      "  1,500 docs  |  4.4s elapsed\n",
      "  2,000 docs  |  5.7s elapsed\n",
      "  2,500 docs  |  7.1s elapsed\n",
      "  3,000 docs  |  8.4s elapsed\n",
      "  3,500 docs  |  9.8s elapsed\n",
      "  4,000 docs  |  11.1s elapsed\n",
      "  4,500 docs  |  12.4s elapsed\n",
      "  5,000 docs  |  13.8s elapsed\n",
      "  5,500 docs  |  15.1s elapsed\n",
      "  6,000 docs  |  16.5s elapsed\n",
      "  6,500 docs  |  17.9s elapsed\n",
      "  7,000 docs  |  19.2s elapsed\n",
      "  7,500 docs  |  20.5s elapsed\n",
      "  8,000 docs  |  21.9s elapsed\n",
      "  8,500 docs  |  23.2s elapsed\n",
      "  9,000 docs  |  24.6s elapsed\n",
      "  9,500 docs  |  26.0s elapsed\n",
      "\n",
      "Ingestion complete: 9,542 docs in 26.1s  (365 docs/s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.14699697494507"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ingest_to_opensearch(rows, batch_size: int = 500):\n",
    "    actions = []\n",
    "    ingested = 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for row in rows:\n",
    "        actions.append({\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_id\":    row[\"restaurant_id\"],\n",
    "            \"_source\": {\n",
    "                \"restaurant_id\":      row[\"restaurant_id\"],\n",
    "                \"name\":               row[\"name\"],\n",
    "                \"cuisines\":           row[\"cuisines\"],\n",
    "                \"location\":           row[\"location\"] if row[\"location\"] else \"\",\n",
    "                \"rating\":             float(row[\"rating\"]) if row[\"rating\"] else 0.0,\n",
    "                \"cost_for_two\":       int(row[\"cost_for_two\"]) if row[\"cost_for_two\"] else 0,\n",
    "                \"text_for_embedding\": row[\"text_for_embedding\"],\n",
    "                \"embedding\":          row[\"embedding\"],\n",
    "            },\n",
    "        })\n",
    "\n",
    "        if len(actions) >= batch_size:\n",
    "            success, errors = bulk(client, actions, raise_on_error=False)\n",
    "            ingested += success\n",
    "            if errors:\n",
    "                print(f\"  {len(errors)} errors in last batch\")\n",
    "            actions = []\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"  {ingested:,} docs  |  {elapsed:.1f}s elapsed\")\n",
    "\n",
    "    # Flush remainder\n",
    "    if actions:\n",
    "        success, _ = bulk(client, actions, raise_on_error=False)\n",
    "        ingested += success\n",
    "\n",
    "    total = time.time() - t0\n",
    "    print(f\"\\nIngestion complete: {ingested:,} docs in {total:.1f}s  ({ingested/total:.0f} docs/s)\")\n",
    "    return total\n",
    "\n",
    "\n",
    "rows = df.collect()\n",
    "ingest_to_opensearch(rows, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a5329",
   "metadata": {},
   "source": [
    "## 5. Verify index stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a80ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index       docs.count store.size\n",
      "restaurants       9542    267.4mb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client.indices.refresh(index=INDEX_NAME)\n",
    "\n",
    "stats = client.cat.indices(index=INDEX_NAME, h=[\"index\", \"docs.count\", \"store.size\"], v=True)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab973d",
   "metadata": {},
   "source": [
    "## 6. Quick sanity query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2281c39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfdc89df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results for 'First Date':\n",
      "  Let's Meet Up                             |  Fast Food, Bakery               |  score 0.6012\n",
      "  Rendezvous Adda                           |  North Indian, Bengali           |  score 0.5938\n",
      "  Hook Up                                   |  North Indian, Continental       |  score 0.5917\n",
      "  Chapter 1 Cafe                            |  Cafe, Italian, Mexican, North Indian, Continental  |  score 0.5916\n",
      "  The Host                                  |  Chinese                         |  score 0.5888\n"
     ]
    }
   ],
   "source": [
    "openai_client = OpenAI()   # Reads OPENAI_API_KEY from env\n",
    "\n",
    "query = \"First Date\"\n",
    "query_vec = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=[query],\n",
    "    dimensions=1024\n",
    ").data[0].embedding\n",
    "\n",
    "resp = client.search(\n",
    "    index=INDEX_NAME,\n",
    "    body={\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"embedding\": {\n",
    "                    \"vector\": query_vec,\n",
    "                    \"k\": 5,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": {\"excludes\": [\"embedding\"]},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Top results for '{query}':\")\n",
    "for hit in resp[\"hits\"][\"hits\"]:\n",
    "    src = hit[\"_source\"]\n",
    "    print(f\"  {src['name']:40s}  |  {src['cuisines']:30s}  |  score {hit['_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73453ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
