{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Embedding Generation\n",
    "\n",
    "Reads the cleaned Delta table, calls the **OpenAI `text-embedding-3-small`** API (1536 dims) in batches from the driver, then writes the result back to `../delta_lake/embeddings/restaurants`.\n",
    "\n",
    "**Tip:** Run on a 50K-row sample first (`SAMPLE = True`) to verify pipeline and check API costs before committing the full dataset.\n",
    "\n",
    "**Cost estimate:** `text-embedding-3-small` is $0.02 / 1M tokens. The Zomato dataset (~500K rows, ~30 tokens each) ≈ 15M tokens ≈ **~$0.30 total**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, StructField, StructType\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set True to run on 50K rows only\n",
    "SAMPLE       = True\n",
    "SAMPLE_SIZE  = 50_000\n",
    "BATCH_SIZE   = 500        # Texts per OpenAI API call (max 2048)\n",
    "\n",
    "DELTA_IN     = \"../delta_lake/raw/restaurants\"\n",
    "DELTA_OUT    = \"../delta_lake/embeddings/restaurants\"\n",
    "MODEL_NAME   = \"text-embedding-3-small\"   # 1536 dims\n",
    "VECTOR_DIM   = 1536\n",
    "\n",
    "# Set your key here or export OPENAI_API_KEY in your shell before launching Jupyter\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fce08e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.3 ready\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ZomatoSemanticSearch-Embeddings\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(f\"Spark {spark.version} ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Delta table → Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on sample: 50,000 rows\n",
      "Pulled 9,542 rows to customer\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.format(\"delta\").load(DELTA_IN)\n",
    "\n",
    "if SAMPLE:\n",
    "    df_spark = df_spark.limit(SAMPLE_SIZE)\n",
    "    print(f\"Running on sample: {SAMPLE_SIZE:,} rows\")\n",
    "else:\n",
    "    print(f\"Full dataset: {df_spark.count():,} rows\")\n",
    "\n",
    "# Pull only the columns we need to the customer\n",
    "df_pd = df_spark.select(\"restaurant_id\", \"text_for_embedding\").toPandas()\n",
    "print(f\"Pulled {len(df_pd):,} rows to customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch embed via OpenAI API\n",
    "\n",
    "OpenAI allows up to **2048 texts per request** — we use `BATCH_SIZE=500` for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3fdd343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()   # Reads OPENAI_API_KEY from env automatically\n",
    "\n",
    "def embed_batch(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"Call OpenAI embeddings API for a batch of texts.\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=MODEL_NAME,\n",
    "        input=texts,\n",
    "        dimensions=1024\n",
    "    )\n",
    "    # Sort by index to guarantee order matches input\n",
    "    return [item.embedding for item in sorted(response.data, key=lambda x: x.index)]\n",
    "\n",
    "\n",
    "def embed_all(texts: list[str], batch_size: int = BATCH_SIZE) -> list[list[float]]:\n",
    "    all_vectors = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        vectors = embed_batch(batch)\n",
    "        all_vectors.extend(vectors)\n",
    "\n",
    "        done = min(i + batch_size, len(texts))\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"  {done:>7,} / {len(texts):,}  |  {elapsed:.1f}s  |  {done/elapsed:.0f} texts/s\")\n",
    "\n",
    "    return all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      500 / 9,542  |  3.1s  |  164 texts/s\n",
      "    1,000 / 9,542  |  6.4s  |  156 texts/s\n",
      "    1,500 / 9,542  |  7.9s  |  190 texts/s\n",
      "    2,000 / 9,542  |  9.3s  |  216 texts/s\n",
      "    2,500 / 9,542  |  10.5s  |  238 texts/s\n",
      "    3,000 / 9,542  |  11.4s  |  264 texts/s\n",
      "    3,500 / 9,542  |  12.8s  |  274 texts/s\n",
      "    4,000 / 9,542  |  14.2s  |  282 texts/s\n",
      "    4,500 / 9,542  |  15.5s  |  289 texts/s\n",
      "    5,000 / 9,542  |  16.8s  |  297 texts/s\n",
      "    5,500 / 9,542  |  18.3s  |  301 texts/s\n",
      "    6,000 / 9,542  |  19.6s  |  306 texts/s\n",
      "    6,500 / 9,542  |  20.8s  |  313 texts/s\n",
      "    7,000 / 9,542  |  22.2s  |  315 texts/s\n",
      "    7,500 / 9,542  |  23.6s  |  318 texts/s\n",
      "    8,000 / 9,542  |  24.9s  |  321 texts/s\n",
      "    8,500 / 9,542  |  26.4s  |  322 texts/s\n",
      "    9,000 / 9,542  |  27.2s  |  330 texts/s\n",
      "    9,500 / 9,542  |  28.6s  |  332 texts/s\n",
      "    9,542 / 9,542  |  29.3s  |  326 texts/s\n",
      "\n",
      "Embedded 9,542 texts in 29.3s\n",
      "Vector dimension: 1024   (expected 1536)\n"
     ]
    }
   ],
   "source": [
    "texts = df_pd[\"text_for_embedding\"].fillna(\"\").tolist()\n",
    "\n",
    "t_start = time.time()\n",
    "embeddings = embed_all(texts)\n",
    "total_time = time.time() - t_start\n",
    "\n",
    "print(f\"\\nEmbedded {len(embeddings):,} texts in {total_time:.1f}s\")\n",
    "print(f\"Vector dimension: {len(embeddings[0])}   (expected {VECTOR_DIM})\") #Had to convert as Opensearch supports only 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attach vectors back to the full Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a small mapping DF: restaurant_id → embedding\n",
    "embed_schema = StructType([\n",
    "    StructField(\"restaurant_id\", StringType(), False),\n",
    "    StructField(\"embedding\", ArrayType(FloatType()), False),\n",
    "])\n",
    "\n",
    "embed_rows = list(zip(df_pd[\"restaurant_id\"].tolist(), embeddings))\n",
    "df_embed = spark.createDataFrame(embed_rows, schema=embed_schema)\n",
    "\n",
    "# Join back onto the full cleaned table\n",
    "df_full = spark.read.format(\"delta\").load(DELTA_IN)\n",
    "if SAMPLE:\n",
    "    df_full = df_full.limit(SAMPLE_SIZE)\n",
    "\n",
    "df_with_embeddings = df_full.join(df_embed, on=\"restaurant_id\", how=\"inner\")\n",
    "# print(f\"Joined rows: {df_with_embeddings.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write to Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/22 22:02:20 WARN TaskSetManager: Stage 20 contains a task of very large size (8609 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../delta_lake/embeddings/restaurants\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_with_embeddings\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .save(DELTA_OUT)\n",
    ")\n",
    "\n",
    "print(f\"Saved to {DELTA_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows : 9,542\n",
      "Restaurant : Shenanigan's Irish Pub\n",
      "Vector dim : 1024\n",
      "First 5 dims: [-0.019657636061310768, -0.005280804820358753, 0.011428858153522015, -0.022064419463276863, -0.009062412194907665]\n"
     ]
    }
   ],
   "source": [
    "df_check = spark.read.format(\"delta\").load(DELTA_OUT)\n",
    "sample_row = df_check.select(\"name\", \"embedding\").first()\n",
    "\n",
    "print(f\"Total rows : {df_check.count():,}\")\n",
    "print(f\"Restaurant : {sample_row['name']}\")\n",
    "print(f\"Vector dim : {len(sample_row['embedding'])}\")\n",
    "print(f\"First 5 dims: {sample_row['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
